{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#INSY 5376 Big Data Analytics - Project - IPL Player Performance Analysis\n",
    "#Team Members :\n",
    "# Amuluru, Sriram Sai\n",
    "# Grandhi, Anish\n",
    "# Potukuchi, Sameer Kumar\n",
    "# Thanikonda, Pruthvi Sai Kumar\n",
    "\n",
    "#Import the required packages\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from collections import namedtuple\n",
    "\n",
    "#Create and initialize Spark Conf, Spark Context and SQL Context\n",
    "conf = SparkConf().setMaster(\"local[*]\").setAppName(\"IPL Data Analysis\")\n",
    "sc = SparkContext(conf = conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "#Read the CSVs and Parse the data\n",
    "deliveriesFields = ('matchID','inning','battingTeam','bowlingTeam','over','ball','batsman','nonStriker','bowler','isSuperOver','wideRuns','byeRuns','legByeRuns','noballRuns','penaltyRuns','batsmanRuns','extraRuns','totalRuns','playerDismissed','dismissalKind','fielder')\n",
    "deliveriesColumns = namedtuple('deliveries',deliveriesFields)\n",
    "def parse(line):\n",
    "    line = line.encode('ascii','ignore')\n",
    "    fields = line.split(\",\")\n",
    "    match_id = fields[0]\n",
    "    inning = fields[1]\n",
    "    batting_team = fields[2]\n",
    "    bowling_team = fields[3]\n",
    "    over = int(fields[4])\n",
    "    ball = int(fields[5])\n",
    "    batsman = fields[6]\n",
    "    non_striker = fields[7]\n",
    "    bowler = fields[8]\n",
    "    is_super_over = fields[9]\n",
    "    wide_runs = fields[10]\n",
    "    bye_runs = fields[11]\n",
    "    legbye_runs = fields[12]\n",
    "    noball_runs = fields[13]\n",
    "    penalty_runs = fields[14]\n",
    "    batsman_runs = int(fields[15])\n",
    "    extra_runs= int(fields[16])\n",
    "    total_runs = int(fields[17])\n",
    "    player_dismissed = fields[18]\n",
    "    dismissal_kind = fields[19]\n",
    "    fielder = fields[20]\n",
    "    return deliveriesColumns(match_id,inning,batting_team,bowling_team,over,ball,batsman,non_striker,bowler,is_super_over,wide_runs,bye_runs,legbye_runs,noball_runs,penalty_runs,batsman_runs,extra_runs,total_runs,player_dismissed,dismissal_kind,fielder)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "deliveriesRDD = sc.textFile('deliveries.csv')\n",
    "deliveriesRDD = deliveriesRDD.filter(lambda x : 'inning' not in x)\n",
    "deliveriesRDD = deliveriesRDD.map(parse)\n",
    "deliveriesDF = sqlContext.createDataFrame(deliveriesRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matchesFields = ('id','season','city','date','team1','team2','tossWinner','tossDecision','result','dlApplied','winner','winByRuns','winByWickets','playerOfMatch','venue','umpire1','umpire2','umpire3')\n",
    "matchesColumns = namedtuple('matches',matchesFields)\n",
    "def parseMatches(line):\n",
    "    line = line.encode('ascii','ignore')\n",
    "    fields = line.split(\",\")\n",
    "    match_id = fields[0]\n",
    "    season = fields[1]\n",
    "    city = fields[2]\n",
    "    date = fields[3]\n",
    "    team1 = fields[4]\n",
    "    team2 = fields[5]\n",
    "    tossWinner = fields[6]\n",
    "    tossDecision = fields[7]\n",
    "    result = fields[8]\n",
    "    dlApplied = fields[9]\n",
    "    winner = fields[10]\n",
    "    winByRuns = fields[11]\n",
    "    winByWickets = fields[12]\n",
    "    playerOfMatch = fields[13]\n",
    "    venue = fields[14]\n",
    "    umpire1 = fields[15]\n",
    "    umpire2= fields[16]\n",
    "    umpire3 = fields[17]\n",
    "    return matchesColumns(match_id,season,city,date,team1,team2,tossWinner,tossDecision,result,dlApplied,winner,winByRuns,winByWickets,playerOfMatch,venue,umpire1,umpire2,umpire3)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "matchesRDD = sc.textFile('matches.csv')\n",
    "matchesRDD = matchesRDD.filter(lambda x : 'season' not in x)\n",
    "matchesRDD = matchesRDD.map(parseMatches)\n",
    "matchesDF = sqlContext.createDataFrame(matchesRDD)\n",
    "matchesDF = matchesDF.drop(matchesDF['umpire3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Joining matches and Deliveries for season specific filtering\n",
    "batsmenDF = matchesDF.join(deliveriesDF, matchesDF.id == deliveriesDF.matchID, \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Import required packages and Create a variable named minimum number of seasons for batsmen, this is the minimum number\n",
    "#of seasons a batsman has featured, the variable will be 1 if the number of seasons is more than 2 and 0 other wise.\n",
    "#This variable will play an important role in regression\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.functions import count, col\n",
    "seasonsDF = batsmenDF.select('batsman','season').distinct().groupBy('batsman').agg(count('season').alias('num_seasons'))\n",
    "function = udf(lambda numSeasons: 1 if numSeasons>=3 else 0, IntegerType())\n",
    "seasonsDF = seasonsDF.select(col('batsman').alias('batsman1'),'num_seasons', function(col('num_seasons')).alias('batsman_min_seasons'))\n",
    "batsmenDF = batsmenDF.join(seasonsDF, batsmenDF.batsman == seasonsDF.batsman1,\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Filter out the data from 2017, the data from 2008 to 2016 forms our training set and the entire data from 2008 to 2017 forms\n",
    "#our test set.\n",
    "batsmenDF2016 = batsmenDF.where('season !=2017')\n",
    "batsmenDF2016 = batsmenDF2016.drop('num_seasons', 'batsman_min_seasons')\n",
    "seasonsDF1 = batsmenDF2016.select('batsman','season').distinct().groupBy('batsman').agg(count('season').alias('num_seasons'))\n",
    "function = udf(lambda numSeasons: 1 if numSeasons>=3 else 0, IntegerType())\n",
    "seasonsDF1 = seasonsDF1.select(col('batsman').alias('batsman1'),'num_seasons', function(col('num_seasons')).alias('batsman_min_seasons'))\n",
    "batsmenDF2016 = batsmenDF2016.join(seasonsDF1, batsmenDF2016.batsman == seasonsDF1.batsman1,\"inner\")\n",
    "batsmenDF2016 = batsmenDF2016.drop('batsman1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Spark SQL Processing to calculate the total number of not outs for a batsman\n",
    "batsmanDF2016Dismissed = batsmenDF2016.where(\"playerDismissed !=''\").collect()\n",
    "batsmanDF2016Dismissed = sqlContext.createDataFrame(batsmanDF2016Dismissed)\n",
    "batsmanDF2016Dismissed = batsmanDF2016Dismissed.select('matchID', 'inning',col('playerDismissed').alias('batsman'),'dismissalKind','fielder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Spark SQL Processing to determine the number of innings a batsman has played.\n",
    "from pyspark.sql.functions import sum\n",
    "batsmenDFGrouped2016 = batsmenDF2016.groupBy('matchID','inning','batsman').agg(sum('batsmanRuns').alias('batsmanRuns'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batsmenDFGrouped2016 = batsmenDFGrouped2016.join(batsmanDF2016Dismissed,['matchID','inning','batsman'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Spark SQL processing to determine the number of not outs for a batsman\n",
    "replaceFunction = udf(lambda fielder: \"-\" if (fielder==None or fielder=='') else fielder)\n",
    "replaceDismissal = udf(lambda dismissal: \"not-out\" if dismissal == None else dismissal)\n",
    "batsmenDFGrouped2016 = batsmenDFGrouped2016.withColumn('fielder',replaceFunction(col('fielder')))\n",
    "batsmenDFGrouped2016 = batsmenDFGrouped2016.withColumn('dismissalKind',replaceDismissal(col('dismissalKind')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Spark SQL Processing to determine the number of innings a batsman has played.\n",
    "num_of_innings = batsmenDFGrouped2016.groupBy('inning','batsman').count()\n",
    "num_of_innings=num_of_innings.groupBy('batsman').agg(sum('count').alias('num_of_innings'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Spark SQL processing to determine the number of not outs for a batsman\n",
    "batsmanDismissal2016DF = batsmenDFGrouped2016.select('dismissalKind','batsman')\n",
    "batsmanDismissal2016DF = batsmanDismissal2016DF.groupBy('batsman','dismissalKind').count()\n",
    "batsmanDismissal2016DF = batsmanDismissal2016DF.where(\"dismissalKind=='not-out'\")\n",
    "batsmanDismissal2016DF = batsmanDismissal2016DF.drop('dismissalKind')\n",
    "batsmanDismissal2016DF = batsmanDismissal2016DF.withColumnRenamed('count','num_not_outs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Spark SQL processing to calculate the batting average of a batsman\n",
    "from pyspark.sql.types import DecimalType\n",
    "import pyspark.sql.functions as func\n",
    "batsmenDFGrouped2016 = batsmenDFGrouped2016.groupBy('batsman').agg(sum('batsmanRuns').alias('batsmanRuns'))\n",
    "batsmenDFGrouped2016 = batsmenDFGrouped2016.join(num_of_innings, ['batsman'])\n",
    "batsmenDFGrouped2016 = batsmenDFGrouped2016.join(batsmanDismissal2016DF, ['batsman'])\n",
    "calculateBattingAverage = udf(lambda batsmanRuns, numInnings, numNotOuts: float(batsmanRuns) / float(numInnings-numNotOuts) if (numInnings-numNotOuts) != 0 else float(0))\n",
    "batsmenDFGrouped2016 = batsmenDFGrouped2016.withColumn('battingAverage', calculateBattingAverage(col('batsmanRuns'), col('num_of_innings'), col('num_not_outs')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Spark SQL processing to round the averge to two decimal places.\n",
    "import pyspark.sql.functions as func\n",
    "batsmenDFGrouped2016 = batsmenDFGrouped2016.withColumn('battingAverage', func.round(col('battingAverage'),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Perform various joins to create a dataframe with all the required batsman stats\n",
    "balls2016 = batsmenDF2016.groupBy('batsman').agg(count('ball').alias('balls'))\n",
    "runs2016 = batsmenDF2016.groupBy('batsman').agg(sum('batsmanRuns').alias('batsmanRuns'))\n",
    "batsmenStats2016 = balls2016.join(runs2016, ['batsman'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Count the number of fours for a batsman\n",
    "fours = batsmenDF2016.where('batsmanRuns == 4')\n",
    "fours = fours.groupBy('batsman').agg(count('batsmanRuns').alias('fours'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fill the null values with 0 since the batsman has not scored any fours.\n",
    "batsmenStats2016 = batsmenStats2016.join(fours, ['batsman'], how = 'left')\n",
    "batsmenStats2016 = batsmenStats2016.na.fill({'fours':0})\n",
    "batsmenStats2016.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Count the number of sixes for a batsman\n",
    "sixes = batsmenDF2016.where('batsmanRuns == 6')\n",
    "sixes = sixes.groupBy('batsman').agg(count('batsmanRuns').alias('sixes'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fill the null values with 0 since the batsman has not scored any sixes\n",
    "batsmenStats2016 = batsmenStats2016.join(sixes, ['batsman'], how = 'left')\n",
    "batsmenStats2016 = batsmenStats2016.na.fill({'sixes':0})\n",
    "batsmenStats2016.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the number of hundreds and number of fifties for a batsman\n",
    "from pyspark.sql.functions import max\n",
    "highestScore2016 = batsmenDF2016.groupBy('batsman', 'matchID').agg(sum('batsmanRuns').alias('highestScore')).drop('matchID')\n",
    "fiftiesDF2016 = highestScore2016.where('highestScore >= 50 AND highestScore <100')\n",
    "hundredsDF2016 = highestScore2016.where('highestScore >= 100')\n",
    "fiftiesDF2016 = fiftiesDF2016.groupBy('batsman').agg(count('highestScore').alias('num_fifties'))\n",
    "hundredsDF2016 = hundredsDF2016.groupBy('batsman').agg(count('highestScore').alias('num_hundreds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the highest score for a batsman across seasons and matches\n",
    "highestScore2016 = highestScore2016.groupBy('batsman').agg(max('highestScore').alias('highestScore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the strike rate for each batsman and round the strikerate to two decimal places.\n",
    "calculateStrikeRate = udf(lambda runs, balls : float(runs)/float(balls) * float(100))\n",
    "batsmenStats2016 = batsmenStats2016.withColumn('strikeRate', calculateStrikeRate(col('batsmanRuns'),col('balls')))\n",
    "batsmenStats2016 = batsmenStats2016.withColumn('strikeRate', func.round(col('strikeRate'),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Add highest score to batsman Stats\n",
    "batsmenStats2016 = batsmenStats2016.join(highestScore2016,['batsman'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Select batsman, batting average, number of innings and number of not outs\n",
    "batsmanSelectStats2016 = batsmenDFGrouped2016.select('batsman','battingAverage','num_of_innings','num_not_outs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#merge the previously selected columns with batsmanstats which is our main dataframe\n",
    "batsmenStats2016 = batsmenStats2016.join(batsmanSelectStats2016, ['batsman'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Get the minimum number of seasons that was calculated previously.\n",
    "minBatsmanSeasons = batsmenDF2016.select('batsman','batsman_min_seasons').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Merge The number of seasons, number of fifties and number of hundreds and replace null values with 0 since the batsman\n",
    "#has not scored any fifties or hundreds.\n",
    "batsmenStats2016 = batsmenStats2016.join(minBatsmanSeasons,['batsman'])\n",
    "batsmenStats2016 = batsmenStats2016.join(fiftiesDF2016, ['batsman'],how ='left')\n",
    "batsmenStats2016 = batsmenStats2016.join(hundredsDF2016, ['batsman'], how = 'left')\n",
    "batsmenStats2016 = batsmenStats2016.na.fill({'num_fifties':0})\n",
    "batsmenStats2016 = batsmenStats2016.na.fill({'num_hundreds':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#View the final dataframe and verify that it has all the required values.\n",
    "batsmenStats2016.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert the dataframe to pandas and write the data to CSV, this is the batsmen training data. \n",
    "batsmenStats2016 = batsmenStats2016.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batsmenStats2016.to_csv('batsmen_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract Bowlers Data\n",
    "from pyspark.sql.functions import count\n",
    "bowlersDF = matchesDF.join(deliveriesDF, matchesDF.id == deliveriesDF.matchID, \"inner\")\n",
    "bowlersDF2016 = bowlersDF.where('season !=2017')\n",
    "bowlersDF2016 = bowlersDF2016.select('matchID','season','bowler','ball','extraRuns','wideRuns','noballRuns','byeRuns','legbyeRuns','totalRuns','playerDismissed', 'dismissalKind','fielder')\n",
    "bowlersDFLegal2016 = bowlersDF2016.where('noballRuns == 0 AND wideRuns ==0')\n",
    "bowlersGroupedDF2016 = bowlersDFLegal2016.groupBy('bowler','ball').agg(count('ball').alias('num_each_ball'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the total balls bowled by a bowler. \n",
    "from pyspark.sql.functions import sum\n",
    "bowlersGroupedDF2016 = bowlersGroupedDF2016.groupBy('bowler').agg(sum('num_each_ball').alias('totalBalls'))\n",
    "bowlersGroupedDF2016.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the total number of runs conceded by a bowler, this does not inclue the byes and legbyes as they are\n",
    "#not calculated towards a bowler, also calculate the number of dot balls. \n",
    "bowlersLegalRunsDF2016 = bowlersDF2016.where('byeRuns == 0 and legByeRuns ==0')\n",
    "runsConceded2016 = bowlersLegalRunsDF2016.groupBy('bowler','totalRuns').agg(count('totalRuns').alias('runs_in_different_ways'))\n",
    "num_dot_balls = runsConceded2016.where(\"totalRuns ==0\")\n",
    "num_dot_balls = num_dot_balls.drop('totalRuns')\n",
    "num_dot_balls = num_dot_balls.withColumnRenamed('runs_in_different_ways','dot_balls')\n",
    "num_dot_balls.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Aggregate the total number of runs for each bowler. \n",
    "from pyspark.sql.functions import udf, col,sum\n",
    "from pyspark.sql.types import IntegerType\n",
    "calculateTotalRuns = udf(lambda typeOfRuns, runsConceded: typeOfRuns*runsConceded, IntegerType()) \n",
    "runsConceded2016 = runsConceded2016.withColumn('total_runs_conceded', calculateTotalRuns(col('totalRuns'),col('runs_in_different_ways')))\n",
    "runsConceded2016 = runsConceded2016.drop('totalRuns','runs_in_different_ways')\n",
    "runsConceded2016 = runsConceded2016.groupBy('bowler').agg(sum('total_runs_conceded').alias('total_runs_conceded'))\n",
    "runsConceded2016.show()\n",
    "\n",
    "                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the total number of extras conceded by each bowler. \n",
    "extras = bowlersDF2016.where(\"wideRuns > 0 OR noballRuns >0\")\n",
    "extras = extras.groupBy('bowler').agg(sum('wideRuns').alias('num_wides'), sum('noballRuns').alias('num_noballs'))\n",
    "extras = extras.withColumn('num_wides', col('num_wides').cast(IntegerType()))\n",
    "extras = extras.withColumn('num_noballs', col('num_noballs').cast(IntegerType()))\n",
    "extras.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the total number of wickets taken by each bowler in 2016, the run outs are not counted towards wickets. \n",
    "wickets2016 = bowlersDF2016.where(\"dismissalKind!='' AND dismissalKind!='run out'\" )\n",
    "wickets2016 = wickets2016.select('bowler','dismissalKind','matchID')\n",
    "totalBowlerWickets2016 = wickets2016.groupBy('bowler').count()\n",
    "totalBowlerWickets2016 = totalBowlerWickets2016.withColumnRenamed('count', 'totalWickets')\n",
    "bestBowling2016 = wickets2016.groupBy('bowler','matchID').count()\n",
    "bestBowling2016 = bestBowling2016.drop('matchID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate the best bowling for each bolwer. \n",
    "from pyspark.sql.functions import max\n",
    "bestBowling2016 = bestBowling2016.groupBy('bowler').agg(max('count').alias('bestBowlingWickets'))\n",
    "bestBowling2016.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlingAverage2016 = runsConceded2016.join(totalBowlerWickets2016,['bowler'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Replace any null values with 0 as this means that the bowler has not taken any wickets. \n",
    "bowlingAverage2016 = bowlingAverage2016.na.fill({'totalWickets':0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the bowling average for each bowler\n",
    "import pyspark.sql.functions as func\n",
    "calculateBowlingAverage = udf(lambda runsConceded, totalWickets: 0 if totalWickets == 0 else float(runsConceded)/float(totalWickets))\n",
    "bowlingAverage2016= bowlingAverage2016.withColumn('bowlingAverage', calculateBowlingAverage(col('total_runs_conceded'),col('totalWickets')))\n",
    "bowlingAverage2016 = bowlingAverage2016.withColumn('bowlingAverage', func.round(col('bowlingAverage'),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlingAverage2016.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the economy rate for each bowler. \n",
    "bowlerEconomy2016 = runsConceded2016.join(bowlersGroupedDF2016, ['bowler'], how='left')\n",
    "calculateOvers = udf(lambda totalBalls: float(totalBalls/6))\n",
    "bowlerEconomy2016 = bowlerEconomy2016.withColumn('num_overs', calculateOvers(col('totalBalls')))\n",
    "bowlerEconomy2016 = bowlerEconomy2016.withColumn('num_overs', func.round(col('num_overs'),1))\n",
    "calculateEconomy = udf(lambda totalRuns, numOvers: 0 if numOvers == 0 else float(totalRuns)/float(numOvers))\n",
    "bowlerEconomy2016 = bowlerEconomy2016.withColumn('bowlerEconomy', calculateEconomy(col('total_runs_conceded'),col('num_overs')))\n",
    "bowlerEconomy2016 = bowlerEconomy2016.withColumn('bowlerEconomy', func.round(col('bowlerEconomy'),2))\n",
    "bowlerEconomy2016.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerStrikeRate2016 = bowlersGroupedDF2016.join(totalBowlerWickets2016, ['bowler'], how='left')\n",
    "bowlerStrikeRate2016.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the bowling strike rate for each bowler. \n",
    "bowlerStrikeRate2016 = bowlerStrikeRate2016.na.fill({'totalWickets':0})\n",
    "calculateBowlerStrikeRate = udf(lambda totalBalls, totalWickets: 0 if totalWickets ==0 else float(totalBalls)/float(totalWickets))\n",
    "bowlerStrikeRate2016 = bowlerStrikeRate2016.withColumn('bowlingStrikeRate', calculateBowlerStrikeRate(col('totalBalls'), col('totalWickets')))\n",
    "bowlerStrikeRate2016 = bowlerStrikeRate2016.withColumn('bowlingStrikeRate', func.round(col('bowlingStrikeRate'),2))\n",
    "bowlerStrikeRate2016.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate the number of seasons each bolwer has featured in, this variable will be 1 if the number of seasons is greater than 2 else 0.\n",
    "seasonsDF2 = bowlersDF2016.select('bowler','season').distinct().groupBy('bowler').agg(count('season').alias('num_seasons'))\n",
    "seasonsFunction = udf(lambda numSeasons: 1 if numSeasons>=3 else 0, IntegerType())\n",
    "seasonsDF2 = seasonsDF2.select('bowler','num_seasons', seasonsFunction(col('num_seasons')).alias('bowler_min_seasons'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Clean the dataframe and merge all the calculated fields into a single data frame.\n",
    "seasonsDF2 = seasonsDF2.drop('num_seasons')\n",
    "seasonsDF2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerStats2016DF = bowlersGroupedDF2016.join(runsConceded2016, ['bowler'], how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerStats2016DF = bowlerStats2016DF.join(totalBowlerWickets2016, ['bowler'], how = 'left')\n",
    "bowlerStats2016DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerStats2016DF = bowlerStats2016DF.na.fill({'totalWickets':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerEconomy2016DF = bowlerEconomy2016.select('bowler','bowlerEconomy')\n",
    "bowlerStats2016DF = bowlerStats2016DF.join(bowlerEconomy2016DF, ['bowler'], how = 'left')\n",
    "bowlerStats2016DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlingAverage2016DF = bowlingAverage2016.select('bowler','bowlingAverage')\n",
    "bowlerStats2016DF = bowlerStats2016DF.join(bowlingAverage2016DF, ['bowler'], how = 'left')\n",
    "bowlerStats2016DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerStrikeRate2016DF = bowlerStrikeRate2016.select('bowler','bowlingStrikeRate')\n",
    "bowlerStats2016DF = bowlerStats2016DF.join(bowlerStrikeRate2016DF, ['bowler'], how='left')\n",
    "bowlerStats2016DF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerStats2016DF = bowlerStats2016DF.join(bestBowling2016, ['bowler'], how = 'left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerStats2016DF = bowlerStats2016DF.na.fill({'bestBowlingWickets':0})\n",
    "bowlerStats2016DF = bowlerStats2016DF.join(num_dot_balls, ['bowler'], how = 'left') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerStats2016DF = bowlerStats2016DF.na.fill({'dot_balls':0})\n",
    "bowlerStats2016DF = bowlerStats2016DF.join(extras, ['bowler'], how = 'left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerStats2016DF = bowlerStats2016DF.na.fill({'num_wides':0})\n",
    "bowlerStats2016DF = bowlerStats2016DF.na.fill({'num_noballs':0})\n",
    "bowlerStats2016DF = bowlerStats2016DF.join(seasonsDF2, ['bowler'], how = 'left')\n",
    "bowlerStats2016DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert the dataframe into pandas dataframe and write the data to CSV, we have our bowlers training data ready. \n",
    "bowlerStats2016DFPandas = bowlerStats2016DF.toPandas()\n",
    "bowlerStats2016DFPandas.to_csv('bowlers_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Batsmen Test Data Extraction, logic remains same as above except the fact that 2017 data is included in the test\n",
    "\n",
    "batsmanDFDismissed = batsmenDF.where(\"playerDismissed !=''\").collect()\n",
    "batsmanDFDismissed = sqlContext.createDataFrame(batsmanDFDismissed)\n",
    "batsmanDFDismissed = batsmanDFDismissed.select('matchID', 'inning',col('playerDismissed').alias('batsman'),'dismissalKind','fielder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "batsmenDFGrouped = batsmenDF.groupBy('matchID','inning','batsman').agg(sum('batsmanRuns').alias('batsmanRuns'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batsmenDFGrouped = batsmenDFGrouped.join(batsmanDFDismissed,['matchID','inning','batsman'], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replaceFunction = udf(lambda fielder: \"-\" if (fielder==None or fielder=='') else fielder)\n",
    "replaceDismissal = udf(lambda dismissal: \"not-out\" if dismissal == None else dismissal)\n",
    "batsmenDFGrouped = batsmenDFGrouped.withColumn('fielder',replaceFunction(col('fielder')))\n",
    "batsmenDFGrouped = batsmenDFGrouped.withColumn('dismissalKind',replaceDismissal(col('dismissalKind')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_of_innings = batsmenDFGrouped.groupBy('inning','batsman').count()\n",
    "num_of_innings=num_of_innings.groupBy('batsman').agg(sum('count').alias('num_of_innings'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batsmanDismissalDF = batsmenDFGrouped.select('dismissalKind','batsman')\n",
    "batsmanDismissalDF = batsmanDismissalDF.groupBy('batsman','dismissalKind').count()\n",
    "batsmanDismissalDF = batsmanDismissalDF.where(\"dismissalKind=='not-out'\")\n",
    "batsmanDismissalDF = batsmanDismissalDF.drop('dismissalKind')\n",
    "batsmanDismissalDF = batsmanDismissalDF.withColumnRenamed('count','num_not_outs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DecimalType\n",
    "import pyspark.sql.functions as func\n",
    "batsmenDFGrouped = batsmenDFGrouped.groupBy('batsman').agg(sum('batsmanRuns').alias('batsmanRuns'))\n",
    "batsmenDFGrouped = batsmenDFGrouped.join(num_of_innings, ['batsman'])\n",
    "batsmenDFGrouped = batsmenDFGrouped.join(batsmanDismissalDF, ['batsman'])\n",
    "calculateBattingAverage = udf(lambda batsmanRuns, numInnings, numNotOuts: float(batsmanRuns) / float(numInnings-numNotOuts) if (numInnings-numNotOuts) != 0 else float(0))\n",
    "batsmenDFGrouped = batsmenDFGrouped.withColumn('battingAverage', calculateBattingAverage(col('batsmanRuns'), col('num_of_innings'), col('num_not_outs')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "batsmenDFGrouped = batsmenDFGrouped.withColumn('battingAverage', func.round(col('battingAverage'),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "balls = batsmenDF.groupBy('batsman').agg(count('ball').alias('balls'))\n",
    "runs = batsmenDF.groupBy('batsman').agg(sum('batsmanRuns').alias('batsmanRuns'))\n",
    "batsmenStats = balls.join(runs, ['batsman'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fours = batsmenDF.where('batsmanRuns == 4')\n",
    "fours = fours.groupBy('batsman').agg(count('batsmanRuns').alias('fours'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batsmenStats = batsmenStats.join(fours, ['batsman'], how = 'left')\n",
    "batsmenStats = batsmenStats.na.fill({'fours':0})\n",
    "batsmenStats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sixes = batsmenDF.where('batsmanRuns == 6')\n",
    "sixes = sixes.groupBy('batsman').agg(count('batsmanRuns').alias('sixes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batsmenStats = batsmenStats.join(sixes, ['batsman'], how = 'left')\n",
    "batsmenStats = batsmenStats.na.fill({'sixes':0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batsmenStats.where(\"batsman == 'CH Gayle'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max\n",
    "highestScore = batsmenDF.groupBy('batsman', 'matchID').agg(sum('batsmanRuns').alias('highestScore')).drop('matchID')\n",
    "fiftiesDF = highestScore.where('highestScore >= 50 AND highestScore <100')\n",
    "hundredsDF = highestScore.where('highestScore >= 100')\n",
    "fiftiesDF = fiftiesDF.groupBy('batsman').agg(count('highestScore').alias('num_fifties'))\n",
    "hundredsDF = hundredsDF.groupBy('batsman').agg(count('highestScore').alias('num_hundreds'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "highestScore = highestScore.groupBy('batsman').agg(max('highestScore').alias('highestScore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "calculateStrikeRate = udf(lambda runs, balls : float(runs)/float(balls) * float(100))\n",
    "batsmenStats = batsmenStats.withColumn('strikeRate', calculateStrikeRate(col('batsmanRuns'),col('balls')))\n",
    "batsmenStats = batsmenStats.withColumn('strikeRate', func.round(col('strikeRate'),2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batsmenStats = batsmenStats.join(highestScore,['batsman'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batsmanSelectStats = batsmenDFGrouped.select('batsman','battingAverage','num_of_innings','num_not_outs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batsmenStats = batsmenStats.join(batsmanSelectStats, ['batsman'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "minBatsmanSeasons = batsmenDF.select('batsman','batsman_min_seasons').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batsmenStats = batsmenStats.join(minBatsmanSeasons,['batsman'])\n",
    "batsmenStats = batsmenStats.join(fiftiesDF, ['batsman'],how ='left')\n",
    "batsmenStats = batsmenStats.join(hundredsDF, ['batsman'], how = 'left')\n",
    "batsmenStats = batsmenStats.na.fill({'num_fifties':0})\n",
    "batsmenStats = batsmenStats.na.fill({'num_hundreds':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batsmenStatsPandas =  batsmenStats.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batsmenStatsPandas.to_csv('batsmen_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Bowlers Test Data Extraction, the logic remains the same except that 2017 data is included in the test dataset\n",
    "from pyspark.sql.functions import count\n",
    "bowlersDF = matchesDF.join(deliveriesDF, matchesDF.id == deliveriesDF.matchID, \"inner\")\n",
    "bowlersDF = bowlersDF.select('matchID','season','bowler','ball','extraRuns','wideRuns','noballRuns','byeRuns','legbyeRuns','totalRuns','playerDismissed', 'dismissalKind','fielder')\n",
    "bowlersDFLegal = bowlersDF.where('noballRuns == 0 AND wideRuns ==0')\n",
    "bowlersGroupedDF = bowlersDFLegal.groupBy('bowler','ball').agg(count('ball').alias('num_each_ball'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum\n",
    "bowlersGroupedDF = bowlersGroupedDF.groupBy('bowler').agg(sum('num_each_ball').alias('totalBalls'))\n",
    "bowlersGroupedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlersLegalRunsDF = bowlersDF.where('byeRuns == 0 and legByeRuns ==0')\n",
    "runsConceded = bowlersLegalRunsDF.groupBy('bowler','totalRuns').agg(count('totalRuns').alias('runs_in_different_ways'))\n",
    "num_dot_balls = runsConceded.where(\"totalRuns ==0\")\n",
    "num_dot_balls = num_dot_balls.drop('totalRuns')\n",
    "num_dot_balls = num_dot_balls.withColumnRenamed('runs_in_different_ways','dot_balls')\n",
    "num_dot_balls.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col,sum\n",
    "from pyspark.sql.types import IntegerType\n",
    "calculateTotalRuns = udf(lambda typeOfRuns, runsConceded: typeOfRuns*runsConceded, IntegerType()) \n",
    "runsConceded = runsConceded.withColumn('total_runs_conceded', calculateTotalRuns(col('totalRuns'),col('runs_in_different_ways')))\n",
    "runsConceded = runsConceded.drop('totalRuns','runs_in_different_ways')\n",
    "runsConceded = runsConceded.groupBy('bowler').agg(sum('total_runs_conceded').alias('total_runs_conceded'))\n",
    "runsConceded.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extras = bowlersDF.where(\"wideRuns > 0 OR noballRuns >0\")\n",
    "extras = extras.groupBy('bowler').agg(sum('wideRuns').alias('num_wides'), sum('noballRuns').alias('num_noballs'))\n",
    "extras = extras.withColumn('num_wides', col('num_wides').cast(IntegerType()))\n",
    "extras = extras.withColumn('num_noballs', col('num_noballs').cast(IntegerType()))\n",
    "extras.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wickets = bowlersDF.where(\"dismissalKind!='' AND dismissalKind!='run out'\" )\n",
    "wicket = wickets.select('bowler','dismissalKind','matchID')\n",
    "totalBowlerWickets = wickets.groupBy('bowler').count()\n",
    "totalBowlerWickets = totalBowlerWickets.withColumnRenamed('count', 'totalWickets')\n",
    "bestBowling = wickets.groupBy('bowler','matchID').count()\n",
    "bestBowling = bestBowling.drop('matchID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import max\n",
    "bestBowling = bestBowling.groupBy('bowler').agg(max('count').alias('bestBowlingWickets'))\n",
    "bestBowling.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bowlingAverage = runsConceded.join(totalBowlerWickets,['bowler'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bowlingAverage = bowlingAverage.na.fill({'totalWickets':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as func\n",
    "calculateBowlingAverage = udf(lambda runsConceded, totalWickets: 0 if totalWickets == 0 else float(runsConceded)/float(totalWickets))\n",
    "bowlingAverage= bowlingAverage.withColumn('bowlingAverage', calculateBowlingAverage(col('total_runs_conceded'),col('totalWickets')))\n",
    "bowlingAverage = bowlingAverage.withColumn('bowlingAverage', func.round(col('bowlingAverage'),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlingAverage.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerEconomy = runsConceded.join(bowlersGroupedDF, ['bowler'], how='left')\n",
    "calculateOvers = udf(lambda totalBalls: float(totalBalls/6))\n",
    "bowlerEconomy = bowlerEconomy.withColumn('num_overs', calculateOvers(col('totalBalls')))\n",
    "bowlerEconomy = bowlerEconomy.withColumn('num_overs', func.round(col('num_overs'),1))\n",
    "calculateEconomy = udf(lambda totalRuns, numOvers: 0 if numOvers == 0 else float(totalRuns)/float(numOvers))\n",
    "bowlerEconomy = bowlerEconomy.withColumn('bowlerEconomy', calculateEconomy(col('total_runs_conceded'),col('num_overs')))\n",
    "bowlerEconomy = bowlerEconomy.withColumn('bowlerEconomy', func.round(col('bowlerEconomy'),2))\n",
    "bowlerEconomy.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerStrikeRate = bowlersGroupedDF.join(totalBowlerWickets, ['bowler'], how='left')\n",
    "bowlerStrikeRate.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerStrikeRate = bowlerStrikeRate.na.fill({'totalWickets':0})\n",
    "calculateBowlerStrikeRate = udf(lambda totalBalls, totalWickets: 0 if totalWickets ==0 else float(totalBalls)/float(totalWickets))\n",
    "bowlerStrikeRate = bowlerStrikeRate.withColumn('bowlingStrikeRate', calculateBowlerStrikeRate(col('totalBalls'), col('totalWickets')))\n",
    "bowlerStrikeRate = bowlerStrikeRate.withColumn('bowlingStrikeRate', func.round(col('bowlingStrikeRate'),2))\n",
    "bowlerStrikeRate.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seasonsDF3 = bowlersDF.select('bowler','season').distinct().groupBy('bowler').agg(count('season').alias('num_seasons'))\n",
    "seasonsFunction = udf(lambda numSeasons: 1 if numSeasons>=3 else 0, IntegerType())\n",
    "seasonsDF3 = seasonsDF3.select('bowler','num_seasons', seasonsFunction(col('num_seasons')).alias('bowler_min_seasons'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seasonsDF3 = seasonsDF3.drop('num_seasons')\n",
    "seasonsDF3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bowlerStatsDF = bowlersGroupedDF.join(runsConceded, ['bowler'], how = 'left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerStatsDF = bowlerStatsDF.join(totalBowlerWickets, ['bowler'], how = 'left')\n",
    "bowlerStatsDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bowlerStatsDF = bowlerStatsDF.na.fill({'totalWickets':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerEconomyDF = bowlerEconomy.select('bowler','bowlerEconomy')\n",
    "bowlerStatsDF = bowlerStatsDF.join(bowlerEconomyDF, ['bowler'], how = 'left')\n",
    "bowlerStatsDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlingAverageDF = bowlingAverage.select('bowler','bowlingAverage')\n",
    "bowlerStatsDF = bowlerStatsDF.join(bowlingAverageDF, ['bowler'], how = 'left')\n",
    "bowlerStatsDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerStrikeRateDF = bowlerStrikeRate.select('bowler','bowlingStrikeRate')\n",
    "bowlerStatsDF = bowlerStatsDF.join(bowlerStrikeRateDF, ['bowler'], how='left')\n",
    "bowlerStatsDF.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bowlerStatsDF = bowlerStatsDF.join(bestBowling, ['bowler'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bowlerStatsDF = bowlerStatsDF.na.fill({'bestBowlingWickets':0})\n",
    "bowlerStatsDF = bowlerStatsDF.join(num_dot_balls, ['bowler'], how = 'left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bowlerStatsDF = bowlerStatsDF.na.fill({'dot_balls':0})\n",
    "bowlerStatsDF = bowlerStatsDF.join(extras, ['bowler'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bowlerStatsDF = bowlerStatsDF.na.fill({'num_wides':0})\n",
    "bowlerStatsDF = bowlerStatsDF.na.fill({'num_noballs':0})\n",
    "bowlerStatsDF = bowlerStatsDF.join(seasonsDF3, ['bowler'], how = 'left')\n",
    "bowlerStatsDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bowlerStatsDFPandas = bowlerStatsDF.toPandas()\n",
    "bowlerStatsDFPandas.to_csv('bowlers_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matchesDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
