{"cells":[{"cell_type":"code","source":["import pandas as pd\ntraining_data = sqlContext.read.load('/FileStore/tables/train.csv',\n                                  format='com.databricks.spark.csv',\n                                  header='true',\n                                  inferSchema='true')\n\n\ntraining_data = training_data.na.drop(subset=['Age','Embarked'])\ntraining_data = training_data.drop('Cabin')\n\npd.DataFrame(training_data.take(3), columns = training_data.columns)\n\ntraining_data.describe().toPandas().transpose()\n\n"],"metadata":{},"outputs":[],"execution_count":1},{"cell_type":"code","source":["from pyspark.ml import Pipeline\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n\ncategoricalColumns = [\"Sex\", \"Embarked\"]\nstages = [] # stages in our Pipeline\nfor column in categoricalColumns:\n  # Category Indexing with StringIndexer\n  stringIndex = StringIndexer(inputCol=column, outputCol=column+\"Index\")\n  # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n  encoder = OneHotEncoder(inputCol=column+\"Index\", outputCol=column+\"classVec\")\n  # Add stages.  These are not run here, but will run all at once later on.\n  stages += [stringIndex, encoder]\n\n  "],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"code","source":["label_stringIndex = StringIndexer(inputCol = \"Survived\", outputCol = \"label\")\nstages += [label_stringIndex]"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["numericCols = [\"Pclass\",\"Age\",\"SibSp\",\"Parch\",\"Fare\"]\nassemblerInputs = map(lambda c: c + \"classVec\", categoricalColumns) + numericCols\nassembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\nstages += [assembler]"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["cols = training_data.columns\n# Create a Pipeline.\npipeline = Pipeline(stages=stages)\n# Run the feature transformations.\n#  - fit() computes feature statistics as needed.\n#  - transform() actually transforms the features.\npipelineModel = pipeline.fit(training_data)\ntraining_data = pipelineModel.transform(training_data)\n\n# Keep relevant columns\nselectedcols = [\"label\", \"features\"] + cols\ntraining_data = training_data.select(selectedcols)\n#display(dataset)\ntype(training_data)\ntraining_data.toPandas()"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\n\n# Create initial LogisticRegression model\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n(trainData, testData) = training_data.randomSplit([0.7, 0.3], seed = 100)\n# Train model with Training Data\nlrModel = lr.fit(trainData)\npredictions = lrModel.transform(testData)\n\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nevaluator.evaluate(predictions)\n#evaluator.getMetricName()"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Create ParamGrid for Cross Validation\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.01, 0.01,0.01])\n             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\n             .addGrid(lr.maxIter, [1, 5, 10])\n             .build())\n\n# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations\ncvModel = cv.fit(trainData)\n"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["predictions = cvModel.transform(testData)\n"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":["evaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier\n\n# Create initial Decision Tree Model\ndt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=9)\n\n# Train model with Training Data\ndtModel = dt.fit(trainData)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["predictions = dtModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["evaluator = BinaryClassificationEvaluator()\nevaluator.evaluate(predictions)\nprint \"numNodes = \", dtModel.numNodes\nprint \"depth = \", dtModel.depth"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(dt.maxDepth, [1,2,6,10])\n             .addGrid(dt.maxBins, [20,40,80])\n             .build())"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"code","source":["cv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations\ncvModel = cv.fit(trainData)\n"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["predictions = cvModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["evaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["print \"numNodes = \", cvModel.bestModel.numNodes\nprint \"depth = \", cvModel.bestModel.depth"],"metadata":{},"outputs":[],"execution_count":17},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\n\n# Create an initial RandomForest model.\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n\n# Train model with Training Data\nrfModel = rf.fit(trainData)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["predictions = rfModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator()\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":20},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(rf.maxDepth, [2, 4, 6])\n             .addGrid(rf.maxBins, [20, 60])\n             .addGrid(rf.numTrees, [5, 20])\n             .build())"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"code","source":["# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations.  This can take about 6 minutes since it is training over 20 trees!\ncvModel = cv.fit(trainData)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["predictions = cvModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["evaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["bestModel = cvModel.bestModel\n# Generate predictions for entire dataset\nfinalPredictions = bestModel.transform(training_data)\n# Evaluate best model\nevaluator.evaluate(finalPredictions)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"code","source":["from pyspark.ml.classification import MultilayerPerceptronClassifier\n\n# Create an initial RandomForest model.\nlayers = [8, 5, 4, 2]\nmp = MultilayerPerceptronClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=200, layers=layers, blockSize=128, seed=1234)\n\n# Train model with Training Data\nmpModel = mp.fit(trainData)"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"code","source":["predictions = mpModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"code","source":["from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n# Evaluate model\nevaluator = MulticlassClassificationEvaluator()\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":29}],"metadata":{"name":"Titanic_Dataset_Analysis","notebookId":3346351859475362},"nbformat":4,"nbformat_minor":0}
